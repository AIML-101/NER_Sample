{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install extra-dependencies\n",
    "!pip -q install git+https://www.github.com/keras-team/keras-contrib.git sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/ac/92c3d2f0b627efbd1a7b2156faa697f9c2bbd7b0fe83ba8a9d36f982156f/pandas-0.25.3-cp36-cp36m-win_amd64.whl (9.0MB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from pandas) (1.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-0.25.3 pytz-2019.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading https://files.pythonhosted.org/packages/44/fb/132de6a4b803d8ce909a89043b7d3f775f64e0a39398fc98c02e3e144b61/matplotlib-3.1.2-cp36-cp36m-win_amd64.whl (9.1MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/64/46/75ab48386cbd56065f5542360562be524ad599911455b6d95520cb118613/kiwisolver-1.1.0-cp36-none-win_amd64.whl\n",
      "Collecting cycler>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
      "Requirement already satisfied: numpy>=1.11 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from matplotlib) (1.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: setuptools in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (42.0.2)\n",
      "Requirement already satisfied: six in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.13.0)\n",
      "Installing collected packages: kiwisolver, cycler, pyparsing, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.2 pyparsing-2.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/fc/37c2706fe0d252e89c49f0c94b94b27878f75a372ca7e5e7ea7583f61c79/scikit_learn-0.22-cp36-cp36m-win_amd64.whl (6.2MB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages (from scikit-learn->sklearn) (1.18.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1321 sha256=449490bda57827774b1a760ac4da1f496a7742c50bcec6fbfd44f1a0de29a7a0\n",
      "  Stored in directory: C:\\Users\\ktgan\\AppData\\Local\\pip\\Cache\\wheels\\76\\03\\bb\\589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "    EPOCHS = 5  # Number of passes through entire dataset\n",
    "    MAX_LEN = 75  # Max length of review (in words)\n",
    "    EMBEDDING = 40  # Dimension of word embedding vector\n",
    "\n",
    "    \n",
    "# Hyperparams for CPU training\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5\n",
    "    MAX_LEN = 75\n",
    "    EMBEDDING = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  47959\n",
      "Number of words in the dataset:  35178\n",
      "Tags: ['I-geo', 'O', 'I-per', 'B-tim', 'B-art', 'I-gpe', 'B-nat', 'I-art', 'I-eve', 'I-nat', 'B-org', 'B-geo', 'B-eve', 'I-org', 'I-tim', 'B-gpe', 'B-per']\n",
      "Number of Labels:  17\n",
      "What the dataset looks like:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1  Sentence: 1             of   IN      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "3  Sentence: 1           have  VBP      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "5  Sentence: 1        through   IN      O\n",
       "6  Sentence: 1         London  NNP  B-geo\n",
       "7  Sentence: 1             to   TO      O\n",
       "8  Sentence: 1        protest   VB      O\n",
       "9  Sentence: 1            the   DT      O"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "\n",
    "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of words in the dataset: \", n_words)\n",
    "\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "print(\"Tags:\", tags)\n",
    "n_tags = len(tags)\n",
    "print(\"Number of Labels: \", n_tags)\n",
    "\n",
    "print(\"What the dataset looks like:\")\n",
    "# Show the first 10 rows\n",
    "data.head(n=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what a sentence looks like:\n",
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "class SentenceGetter(object):\n",
    "    \"\"\"Class to Get the sentence in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_1, Tag_1)]\"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Args:\n",
    "            data is the pandas.DataFrame which contains the above dataset\"\"\"\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        \"\"\"Return one sentence\"\"\"\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "print('This is what a sentence looks like:')\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get all the sentences\n",
    "sentences = getter.sentences\n",
    "\n",
    "# Plot sentence by lenght\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.title('Token per sentence')\n",
    "plt.xlabel('Len (number of token)')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word Obama is identified by the index: 33081\n",
      "The labels B-geo(which defines Geopraphical Enitities) is identified by the index: 12\n",
      "Raw Sample:  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "Raw Label:  O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "After processing, sample: [24359 29436 21411 22061 22206 18264 31078 17398 28289 14789 19265 17491\n",
      " 20900  3939 20212 14789 22520 29436 24425 13661 26030 16681 13897 33710\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "After processing, labels: [[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Key:word -> Value:token_index\n",
    "# The first 2 entries are reserved for PAD and UNK\n",
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1 # Unknown words\n",
    "word2idx[\"PAD\"] = 0 # Padding\n",
    "\n",
    "# Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "# Vocabulary Key:Label/Tag -> Value:tag_index\n",
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "print(\"The word Obama is identified by the index: {}\".format(word2idx[\"Obama\"]))\n",
    "print(\"The labels B-geo(which defines Geopraphical Enitities) is identified by the index: {}\".format(tag2idx[\"B-geo\"]))\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Convert each sentence from list of Token to list of word_index\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same lenght\n",
    "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
    "\n",
    "# Convert Tag/Label to tag_index\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "# Padding each sentence to have the same lenght\n",
    "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "# One-Hot encode\n",
    "y = [to_categorical(i, num_classes=n_tags+1) for i in y]  # n_tags+1(PAD)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n",
    "\n",
    "print('Raw Sample: ', ' '.join([w[0] for w in sentences[0]]))\n",
    "print('Raw Label: ', ' '.join([w[2] for w in sentences[0]]))\n",
    "print('After processing, sample:', X[0])\n",
    "print('After processing, labels:', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 40)            1407200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 100)           36400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 75, 18)            1278      \n",
      "=================================================================\n",
      "Total params: 1,449,928\n",
      "Trainable params: 1,449,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "# Model definition\n",
    "input = Input(shape=(MAX_LEN,))\n",
    "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
    "                  input_length=MAX_LEN)(input)  # default: 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 36s - loss: 0.5270 - crf_viterbi_accuracy: 0.8677 - val_loss: 0.2351 - val_crf_viterbi_accuracy: 0.9515\n",
      "Epoch 2/5\n",
      " - 29s - loss: 0.2076 - crf_viterbi_accuracy: 0.9541 - val_loss: 0.1539 - val_crf_viterbi_accuracy: 0.9560\n",
      "Epoch 3/5\n",
      " - 29s - loss: 0.1122 - crf_viterbi_accuracy: 0.9661 - val_loss: 0.0825 - val_crf_viterbi_accuracy: 0.9784\n",
      "Epoch 4/5\n",
      " - 29s - loss: 0.0647 - crf_viterbi_accuracy: 0.9822 - val_loss: 0.0526 - val_crf_viterbi_accuracy: 0.9856\n",
      "Epoch 5/5\n",
      " - 30s - loss: 0.0434 - crf_viterbi_accuracy: 0.9876 - val_loss: 0.0394 - val_crf_viterbi_accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "pred_cat = model.predict(X_te)\n",
    "pred = np.argmax(pred_cat, axis=-1)\n",
    "y_te_true = np.argmax(y_te, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        40\n",
      "       B-eve       0.00      0.00      0.00        30\n",
      "       B-geo       0.78      0.89      0.83      3670\n",
      "       B-gpe       0.95      0.91      0.93      1586\n",
      "       B-nat       0.00      0.00      0.00        27\n",
      "       B-org       0.72      0.63      0.67      1983\n",
      "       B-per       0.82      0.73      0.77      1712\n",
      "       B-tim       0.89      0.80      0.84      2033\n",
      "       I-art       0.00      0.00      0.00        23\n",
      "       I-eve       0.00      0.00      0.00        16\n",
      "       I-geo       0.80      0.61      0.69       744\n",
      "       I-gpe       0.00      0.00      0.00        24\n",
      "       I-nat       0.00      0.00      0.00         6\n",
      "       I-org       0.74      0.72      0.73      1577\n",
      "       I-per       0.80      0.84      0.82      1753\n",
      "       I-tim       0.85      0.52      0.65       670\n",
      "           O       0.98      0.99      0.99     88482\n",
      "         PAD       1.00      1.00      1.00    255324\n",
      "\n",
      "    accuracy                           0.99    359700\n",
      "   macro avg       0.52      0.48      0.50    359700\n",
      "weighted avg       0.99      0.99      0.99    359700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "# Convert the index to tag\n",
    "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
    "y_te_true_tag = [[idx2tag[i] for i in row] for row in y_te_true] \n",
    "\n",
    "report = flat_classification_report(y_pred=pred_tag, y_true=y_te_true_tag)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving Vocab\n",
    "with open('models/w1.pickle', 'wb') as handle:\n",
    "    pickle.dump(word2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    " \n",
    "# Saving Vocab\n",
    "with open('models/t1.pickle', 'wb') as handle:\n",
    "    pickle.dump(tag2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Saving Model Weight\n",
    "model.save_weights('models/tr1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/tr1_m1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import  crf_loss\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model = load_model('models/tr1_m1.h5', custom_objects={'CRF':CRF, \n",
    "                                                  'crf_loss':crf_loss, \n",
    "                                                  'crf_viterbi_accuracy':crf_viterbi_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 40)            1407200   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 100)           36400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 75, 18)            1278      \n",
      "=================================================================\n",
      "Total params: 1,449,928\n",
      "Trainable params: 1,449,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-31 02:19:23.108567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\ktgan\\appdata\\local\\programs\\python\\python36\\Lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\ktgan\\appdata\\local\\programs\\python\\python36\\Lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"G:\\ML_Space\\Workspace\\NER\\test_ner\\Scripts\\tflite_convert.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\lite\\python\\tflite_convert.py\", line 515, in main\n",
      "    app.run(main=run_main, argv=sys.argv[:1])\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\absl\\app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\lite\\python\\tflite_convert.py\", line 511, in run_main\n",
      "    _convert_tf1_model(tflite_flags)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\lite\\python\\tflite_convert.py\", line 124, in _convert_tf1_model\n",
      "    converter = _get_toco_converter(flags)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\lite\\python\\tflite_convert.py\", line 111, in _get_toco_converter\n",
      "    return converter_fn(**converter_kwargs)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 820, in from_keras_model_file\n",
      "    keras_model = _keras.models.load_model(model_file, custom_objects)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\", line 146, in load_model\n",
      "    loader_impl.parse_saved_model(filepath)\n",
      "  File \"g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\loader_impl.py\", line 83, in parse_saved_model\n",
      "    constants.SAVED_MODEL_FILENAME_PB))\n",
      "OSError: SavedModel file does not exist at: 'models/tr1_m1.h5'/{saved_model.pbtxt|saved_model.pb}\n"
     ]
    }
   ],
   "source": [
    "!tflite_convert --output_file='models/tr1_m1.tflite' --keras_model_file='models/tr1_m1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# This line must be executed before loading Keras model.\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'crf_1_2/one_hot:0' shape=(?, ?, 18) dtype=float32>]\n",
      "[<tf.Tensor 'input_1_4:0' shape=(?, 75) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "reload_model = load_model('models/tr1_m1.h5', custom_objects={'CRF':CRF, \n",
    "                                                  'crf_loss':crf_loss, \n",
    "                                                  'crf_viterbi_accuracy':crf_viterbi_accuracy})\n",
    "print(reload_model.outputs)\n",
    "# [<tf.Tensor 'dense_2/Softmax:0' shape=(?, 10) dtype=float32>]\n",
    "print(reload_model.inputs)\n",
    "# [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-34-51e1dfb94bd3>:31: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From g:\\ml_space\\workspace\\ner\\test_ner\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 96 variables.\n",
      "INFO:tensorflow:Converted 96 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in reload_model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models\\\\tf_model1.pb'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(frozen_graph, \"models\", \"tf_model1.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tflite_convert --output_file='models/tfl_model1.tflite' --graph_def_file='models/tf_model1.pb' --input_arrays=embedding_1/embeddings --output_arrays=training_2/RMSprop/Variable_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output name = \n",
      "training_2/RMSprop/Variable_13\n",
      "\n",
      "Input name = \n",
      "embedding_1/embeddings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gf = tf.GraphDef()   \n",
    "m_file = open('models/tf_model1.pb','rb')\n",
    "gf.ParseFromString(m_file.read())\n",
    "\n",
    "with open('somefile.txt', 'a') as the_file:\n",
    "    for n in gf.node:\n",
    "        the_file.write(n.name+'\\n')\n",
    "\n",
    "file = open('somefile.txt','r')\n",
    "data = file.readlines()\n",
    "print(\"output name = \")\n",
    "print (data[len(data)-1])\n",
    "\n",
    "print (\"Input name = \")\n",
    "file.seek ( 0 )\n",
    "print (file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner_tf1.15",
   "language": "python",
   "name": "ner_tf1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
